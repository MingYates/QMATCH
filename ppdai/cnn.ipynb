{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-13T01:04:11.799Z"
    }
   },
   "outputs": [],
   "source": [
    "from ppdai_utils import *\n",
    "import pickle\n",
    "\n",
    "cdict, emat = embedding('/files/faust/COMPETITION/ppdai/char_embed.txt')\n",
    "questions = pickle.load(open('/files/faust/COMPETITION/ppdai/questions.pkl', 'rb'))\n",
    "trainpair = readtrain_extend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-13T01:05:07.924Z"
    }
   },
   "outputs": [],
   "source": [
    "charlen = [len(wc['cchars']) for _,wc in questions.items()]\n",
    "print(max(charlen))\n",
    "charlen = [len(wc['cwords']) for _,wc in questions.items()]\n",
    "print(max(charlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T02:28:42.419276Z",
     "start_time": "2018-06-13T02:28:37.771170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508772\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 60\n",
    "trainpair_idx = []\n",
    "for q0, q1, l in trainpair:\n",
    "    q0_chars = questions[q0]['cchars']\n",
    "    q1_chars = questions[q1]['cchars']\n",
    "    q0_idx = sent2idx(q0_chars, cdict, MAX_SEQUENCE_LENGTH)\n",
    "    q1_idx = sent2idx(q1_chars, cdict, MAX_SEQUENCE_LENGTH)\n",
    "    trainpair_idx.append((q0_idx, q1_idx, l))\n",
    "print(len(trainpair_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T02:34:03.595395Z",
     "start_time": "2018-06-13T02:34:03.591121Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T03:18:37.600173Z",
     "start_time": "2018-06-13T03:18:36.664476Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_keras_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2615e4baa33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_q2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[1;32m     62\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0mnodes_in_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m             \u001b[0mbuild_map_of_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_in_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mbuild_map_of_graph\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 build_map_of_graph(x, finished_nodes, nodes_in_progress,\n\u001b[0;32m-> 1724\u001b[0;31m                                    layer, node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mbuild_map_of_graph\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 build_map_of_graph(x, finished_nodes, nodes_in_progress,\n\u001b[0;32m-> 1724\u001b[0;31m                                    layer, node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mbuild_map_of_graph\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \"\"\"\n\u001b[1;32m   1694\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnode_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_keras_history'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers import concatenate, Flatten\n",
    "from keras.layers import Lambda\n",
    "embedding_layer = Embedding(len(cdict),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[emat],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "layer_conv_1_1 = Conv1D(64, 1, activation='tanh')\n",
    "layer_conv_1_2 = Conv1D(64, 2, activation='tanh')\n",
    "layer_conv_1_3 = Conv1D(64, 3, activation='tanh')\n",
    "layer_conv_1_5 = Conv1D(64, 5, activation='tanh')\n",
    "layer_fc_1 = Dense(256, activation=\"tanh\")\n",
    "layer_lr = Dense(1, activation='sigmoid')\n",
    "\n",
    "input_q1 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "input_q2 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "q1_embed = embedding_layer(input_q1)\n",
    "q2_embed = embedding_layer(input_q2)\n",
    "\n",
    "# for q1\n",
    "q1_conv_1_1 = layer_conv_1_1(q1_embed)\n",
    "q1_conv_1_2 = layer_conv_1_2(q1_embed)\n",
    "q1_conv_1_3 = layer_conv_1_3(q1_embed)\n",
    "q1_conv_1_5 = layer_conv_1_5(q1_embed)\n",
    "q1_pool_1_1 = MaxPooling1D(3)(q1_conv_1_1)\n",
    "q1_pool_1_1 = Flatten()(q1_pool_1_1)\n",
    "q1_pool_1_2 = MaxPooling1D(3)(q1_conv_1_2)\n",
    "q1_pool_1_2 = Flatten()(q1_pool_1_2)\n",
    "q1_pool_1_3 = MaxPooling1D(3)(q1_conv_1_3)\n",
    "q1_pool_1_3 = Flatten()(q1_pool_1_3)\n",
    "q1_pool_1_5 = MaxPooling1D(3)(q1_conv_1_5)\n",
    "q1_pool_1_5 = Flatten()(q1_pool_1_5)\n",
    "q1_merged = concatenate([q1_pool_1_1, q1_pool_1_2, q1_pool_1_3, q1_pool_1_5])\n",
    "q1_fc_1 = layer_fc_1(q1_merged)\n",
    "\n",
    "# for q2\n",
    "q2_conv_1_1 = layer_conv_1_1(q2_embed)\n",
    "q2_conv_1_2 = layer_conv_1_2(q2_embed)\n",
    "q2_conv_1_3 = layer_conv_1_3(q2_embed)\n",
    "q2_conv_1_5 = layer_conv_1_5(q2_embed)\n",
    "q2_pool_1_1 = MaxPooling1D(3)(q2_conv_1_1)\n",
    "q2_pool_1_1 = Flatten()(q2_pool_1_1)\n",
    "q2_pool_1_2 = MaxPooling1D(3)(q2_conv_1_2)\n",
    "q2_pool_1_2 = Flatten()(q2_pool_1_2)\n",
    "q2_pool_1_3 = MaxPooling1D(3)(q2_conv_1_3)\n",
    "q2_pool_1_3 = Flatten()(q2_pool_1_3)\n",
    "q2_pool_1_5 = MaxPooling1D(3)(q2_conv_1_5)\n",
    "q2_pool_1_5 = Flatten()(q2_pool_1_5)\n",
    "q2_merged = concatenate([q2_pool_1_1, q2_pool_1_2, q2_pool_1_3, q2_pool_1_5])\n",
    "q2_fc_1 = layer_fc_1(q2_merged)\n",
    "\n",
    "# fusing q0, q1\n",
    "q12 = Lambda(lambda x: x ** 2)(q1_fc_1 - q2_fc_1)\n",
    "pred = layer_lr(q12)\n",
    "\n",
    "model = Model([input_q1, input_q2], pred)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-12T06:46:40.261Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "DROPOUT = 0.5\n",
    "MAX_SEQUENCE_LENGTH = 60\n",
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "q1 = Embedding(len(cdict),\n",
    "                 EMBEDDING_DIM,\n",
    "                 weights=[word_embedding_matrix],\n",
    "                 input_length=MAX_SEQUENCE_LENGTH,\n",
    "                 trainable=False)(question1)\n",
    "q1 = Conv1D(256, 5, activation='relu')(q1)\n",
    "q1 = MaxPooling1D(5)(q1)\n",
    "q1 = Flatten()(q1)\n",
    "q1 = Dense(128, activation=\"relu\")(q1)\n",
    "#q1 = Dropout(0.5)(q1)\n",
    "\n",
    "q2 = Embedding(len(cdict),\n",
    "                 EMBEDDING_DIM,\n",
    "                 weights=[word_embedding_matrix],\n",
    "                 input_length=MAX_SEQUENCE_LENGTH,\n",
    "                 trainable=False)(question2)\n",
    "q2 = Conv1D(256, 5, activation='relu')(q2)\n",
    "q2 = MaxPooling1D(5)(q2)\n",
    "q2 = Flatten()(q2)\n",
    "q2 = Dense(128, activation=\"relu\")(q2)\n",
    "#q2 = Dropout(0.5)(q2)\n",
    "merged = concatenate([q1,q2])\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.test split\n",
    "import random\n",
    "random.shuffle(trainpair_idx)\n",
    "\n",
    "train_pair = trainpair_idx[:int(len(trainpair_idx)*0.9)]\n",
    "test_pair = trainpair_idx[int(len(trainpair_idx)*0.9):]\n",
    "train_q1 = [p[0] for p in train_pair]\n",
    "train_q2 = [p[1] for p in train_pair]\n",
    "train_y = [p[2] for p in train_pair]\n",
    "val_q1 = [p[0] for p in test_pair]\n",
    "val_q2 = [p[1] for p in test_pair]\n",
    "val_y = [p[2] for p in test_pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([train_q1, train_q2], train_y, validation_data=([val_q1, val_q2], val_y), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size = [1, 2, 3, 5]\n",
    "layer_conv_c1 = [Conv1D(64, size, activation='relu', padding='same') for size in filter_size]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
